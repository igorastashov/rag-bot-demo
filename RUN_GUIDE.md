## Запуск сервисов и приложения (краткий чек‑лист)

Этот файл служит **краткой шпаргалкой** по запуску всех частей системы.  
Подробная настройка инфраструктуры (vLLM, bge‑m3, Chroma, Neo4j) описана в `INFRA_SETUP.md`.

---

## 1. Предусловия

- **LLM‑сервис (Qwen/vLLM)**: поднят и доступен по `LLM_BASE_URL` из `.env`.  
- **Neo4j**: контейнер запущен и доступен по `NEO4J_URI` из `.env`.  
- **Эмбеддер `bge-m3`**: модель лежит по пути `EMBEDDER_MODEL_PATH` из `.env`.  
- **Chroma DB**: достаточно, чтобы существовала (или создавалась) директория `CHROMA_DB_PATH` из `.env`.

Если что‑то из этого не готово — сначала пройти шаги в `INFRA_SETUP.md`.

---

## 2. Локальный запуск (Windows, разработка)

- **Создать и активировать виртуальное окружение** (один раз на проект):

```bash
cd D:/__projects__/drop-rag
python -m venv .venv

# Git Bash
source .venv/Scripts/activate
# или PowerShell
# .\.venv\Scripts\activate
```

- **Установить зависимости** (после активации `.venv`):

```bash
pip install -r requirements.txt
```

- **Создать `.env` в корне** (минимальный пример):

```env
LLM_BASE_URL=http://192.168.52.119:8000/v1
LLM_API_KEY=dummy
LLM_MODEL_NAME=qwen-4b-instruct

EMBEDDER_MODEL_PATH=./models/bge-m3
EMBEDDER_DEVICE=cpu        # или cuda:0 / cuda:1 при готовом CUDA-окружении

CHROMA_DB_PATH=./data/chroma_db

NEO4J_URI=bolt://192.168.52.119:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=test1234

PDF_STORAGE_ROOT=./data/pdf_storage
RAG_SCOPE=session          # или global
```

- **Запустить Streamlit‑приложение**:

```bash
(.venv) streamlit run ui/app.py
```

После этого приложение будет доступно по адресу, который покажет Streamlit (обычно `http://localhost:8501`).

---

## 3. Базовый сценарий проверки приложения

- **Новый чат**:
  - открыть страницу;
  - при необходимости нажать кнопку **«Новый чат»** в сайдбаре.
- **Задать вопрос без PDF**:
  - в поле чата написать вопрос (например, "Привет") и проверить, что приходит ответ от Qwen.
- **Загрузить PDF и проиндексировать**:
  - в блоке `1. Загрузка PDF` выбрать один или несколько файлов;
  - нажать кнопку **«Индексировать загруженные PDF»** и дождаться завершения прогресса.
- **Задать вопрос по содержимому PDF**:
  - в чате задать вопрос, который можно ответить на основе загруженного документа;
  - убедиться, что ответ ссылается на содержимое PDF (по логам видно, что происходил поиск в Chroma).

---

## 4. Будущие сценарии (контейнеризация)

В дальнейшем здесь можно будет добавить:

- **Команды сборки Docker‑образов** для:
  - backend (Python + Streamlit + наше приложение),
  - вспомогательных служб (если появятся отдельные сервисы);
- **Примеры `docker-compose.yml`** для запуска всего стека одной командой;
- **Команды деплоя** на целевой сервер (машина с двумя GPU, где уже крутятся vLLM и Neo4j).

До тех пор актуален сценарий разработки из раздела 2.


